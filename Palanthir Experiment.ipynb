{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "class Palanthir(object):\n",
    "\n",
    "    def __init__(self, input):\n",
    "        \"\"\"Initiates a Palanthir-class on-top a Pandas Dataframe. The class-attributes describes the overall structure and composition of the data\"\"\"\n",
    "        self.input_data = input\n",
    "        self.output = self.input_data.copy(deep=True)\n",
    "        self.observations = len(self.output)\n",
    "        self.features = list(self.output)\n",
    "        self.features_num = list(self.output.loc[:, self.output.dtypes != object])\n",
    "        self.features_cat = list(self.output.loc[:, self.output.dtypes == object])\n",
    "        self.train_subset = []\n",
    "        self.test_subset = []\n",
    "        self.current_version = 0\n",
    "        self.transformation_history = [dict(version=0,transformation='input',result=self.input_data)]\n",
    "        self.pipeline = [Pipeline([])]\n",
    "\n",
    "    def update_attributes(self):\n",
    "        self.observations = len(self.output)\n",
    "        self.features = list(self.output)\n",
    "        self.features_num = list(self.output.loc[:, self.output.dtypes != object])\n",
    "        self.features_cat = list(self.output.loc[:, self.output.dtypes == object])\n",
    "\n",
    "    def update_history(self, step=None, snapshot=None,versionOverwrite=None):\n",
    "        self.current_version += 1 if versionOverwrite == None else versionOverwrite\n",
    "        self.transformation_history.append(dict(version=self.current_version,transformation=step,result=snapshot))\n",
    "\n",
    "    def update_pipeline(self,pip_step=None,pip_transformer=None):\n",
    "        self.pipeline.append(self.pipeline[-1].steps.append([pip_step,pip_transformer]))\n",
    "\n",
    "    def restore(self, toVersion:int=-1):\n",
    "        versionCheckpoint = (self.current_version - 1) if toVersion == -1 else toVersion\n",
    "        self.current_version = versionCheckpoint\n",
    "        self.output = self.transformation_history[versionCheckpoint].get('result')\n",
    "        self.update_attributes\n",
    "        self.update_history(step=f\"Restored to version {versionCheckpoint}\",snapshot=self.output,versionOverwrite=versionCheckpoint)\n",
    "\n",
    "    def summarize(self):\n",
    "        \"\"\"Prints the info, description and any missing value-counts for the class\"\"\"\n",
    "        dataset = self.output\n",
    "        return print(\n",
    "            \"Info: \", dataset.info(),\n",
    "            \"Description: \", dataset.describe(),\n",
    "            \"Missing values: \", dataset.isna().sum()\n",
    "        )\n",
    "\n",
    "    def random_split(self, test_size, store=True):\n",
    "        \"\"\"Uses the SKLearn Train_Test_Split to divide the dataset into random training and test subset\"\"\"\n",
    "        dataset = self.output\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        train, test = train_test_split(dataset, test_size=test_size, random_state=42)\n",
    "        if store:\n",
    "            self.train_subset, self.test_subset = [train], [test]\n",
    "        return train, test\n",
    "\n",
    "    def stratified_split(self, cols, store=True):\n",
    "        \"\"\"Uses the SKLearn StratigiesShuffleSplit to divide the dataset into stratified training and test subset\"\"\"\n",
    "        dataset = self.output\n",
    "        from sklearn.model_selection import StratifiedShuffleSplit\n",
    "        split = StratifiedShuffleSplit(n_split=1, test_size=0.2, random_state=42)\n",
    "        for train_index, test_index in split.split(dataset, dataset[cols]):\n",
    "            strat_train_set = dataset.loc[train_index]\n",
    "            strat_test_set = dataset.loc[test_index]\n",
    "        if store:\n",
    "            self.train_subset, self.test_subset = [strat_train_set], [strat_test_set]\n",
    "        return strat_train_set, strat_test_set\n",
    "\n",
    "    def PCA(self, n_components=0.80, store=True):\n",
    "        dataset = self.output[self.features_num]\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca_data = PCA(n_components=n_components).fit_transform(dataset)\n",
    "        output_df = pd.DataFrame(pca_data, columns=[\"PCA_\" + str(col + 1) for col in range(pca_data.shape[1])],index=dataset.index)\n",
    "        if store:\n",
    "            self.output = output_df\n",
    "            self.update_attributes()\n",
    "            self.update_history(step=\"Performed Principal Component Analysis\",snapshot=self.output)\n",
    "        explained_variance = PCA().fit(dataset).explained_variance_ratio_\n",
    "        cumsum = np.cumsum(explained_variance)\n",
    "        print(cumsum)\n",
    "        plt.plot([\"PCA\" + str(num) for num in range(1, len(cumsum) + 1)], cumsum)\n",
    "        plt.show()\n",
    "        return output_df\n",
    "\n",
    "    def fill_nulls(self, strategy=\"median\", store=True):\n",
    "        \"\"\"Uses the SKLearn SimpleImputer to fill out any missing values in the numerical features of the dataset\"\"\"\n",
    "        dataset = self.output[self.features_num]\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        imputed_data = SimpleImputer(strategy=strategy).fit_transform(dataset)\n",
    "        output_df = pd.DataFrame(imputed_data, columns=dataset.columns, index=dataset.index)\n",
    "        if store:\n",
    "            self.output[self.features_num] = output_df\n",
    "            self.update_attributes()\n",
    "            self.update_history(step=\"Filled nulls\",snapshot=self.output)\n",
    "        return output_df\n",
    "\n",
    "    def encode_order(self, store=True):\n",
    "        \"\"\"Uses the SKLearn OrdinalEncoder to order any categorical features of the dataset\"\"\"\n",
    "        dataset = self.output[self.features_cat]\n",
    "        from sklearn.preprocessing import OrdinalEncoder\n",
    "        encoded_data = OrdinalEncoder().fit_transform(dataset)\n",
    "        output_df = pd.DataFrame(encoded_data, columns=dataset.columns, index=dataset.index)\n",
    "        if store:\n",
    "            self.output[self.features_cat] = output_df\n",
    "            self.update_attributes()\n",
    "            self.update_history(step=\"Encoded order of categorial features\",snapshot=self.output)\n",
    "        return output_df\n",
    "\n",
    "    def make_dummies(self, store=True):\n",
    "        \"\"\"Uses the SKLearn OneHotEncoder to turn categorical features of the dataset into dummy-variables\"\"\"\n",
    "        dataset = self.output[self.features_cat]\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        encoder = OneHotEncoder().fit(dataset)\n",
    "        new_column_names = encoder.get_feature_names_out(dataset.columns)\n",
    "        dummy_data = encoder.transform(dataset).toarray()\n",
    "        dummy_data_df = pd.DataFrame(dummy_data, columns=[name for name in new_column_names], index=dataset.index)\n",
    "        output_df = pd.merge(self.output[self.features_num], dummy_data_df, left_index=True, right_index=True)\n",
    "        if store == True:\n",
    "            self.output = output_df\n",
    "            self.update_attributes()\n",
    "            self.update_history(step=\"Turned categorical features into dummy variables\",snapshot=self.output)\n",
    "        return output_df\n",
    "\n",
    "    def scale(self, strategy:str, store=True):\n",
    "        \"\"\"Uses the SKLearn StandardScaler or MinMaxScaler to scale all numerical features of the dataset\"\"\"\n",
    "        dataset = self.output[self.features_num]\n",
    "        from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "        if strategy==\"Standard\":\n",
    "            scaler = StandardScaler()\n",
    "        elif strategy==\"MinMax\":\n",
    "            scaler = MinMaxScaler()\n",
    "        else:\n",
    "            print('Not a proper scaler')\n",
    "        output_df = scaler.fit_transform(dataset)\n",
    "        if store:\n",
    "            self.output[self.features_num] = output_df\n",
    "            self.update_attributes()\n",
    "            self.update_history(step=f\"\"\"Scaled feature-values using {'Standard-scaler' if strategy=='Standard' else 'MinMax-scaler'}\"\"\",snapshot=self.output)\n",
    "        return output_df\n",
    "\n",
    "    def cluster(self, max_k=10, store=True):\n",
    "        \"\"\"Uses the SKLearn KMeans to cluster the dataset\"\"\"\n",
    "        dataset = self.output\n",
    "        from sklearn.cluster import KMeans\n",
    "        from matplotlib import pyplot\n",
    "        from sklearn.metrics import silhouette_score\n",
    "        kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(dataset) for k in range(1, max_k + 1)]\n",
    "        silhouettes = [silhouette_score(dataset, model.labels_) for model in kmeans_per_k[1:]]\n",
    "        best_k = silhouettes.index(max(silhouettes)) + 2\n",
    "        plt.plot(range(2, max_k + 1), silhouettes)\n",
    "        plt.xlabel(\"KMeans\")\n",
    "        plt.ylabel(\"Silhouette-score\")\n",
    "        plt.show()\n",
    "        print(\"Best silhouette is obtained with k as: \", best_k)\n",
    "        if store:\n",
    "            self.output[\"Cluster\"] = [\"Cluster \" + str(i) for i in KMeans(n_clusters=best_k, random_state=42).fit_predict(dataset)]\n",
    "            self.update_attributes()\n",
    "            self.update_history(step=\"Added Cluster-label as column to dataset\",snapshot=self.output)\n",
    "        return self.output\n",
    "\n",
    "    def construct_pipeline(self):\n",
    "        \"\"\"Uses the SKLearn Pipeline and ColumnTransformer to construct a pipeline of transformations on the dataset - including filling out zeroes, scaling and dummifying\"\"\"\n",
    "        dataset = self.output\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        num_columns = []\n",
    "        cat_columns = []\n",
    "        num_pipeline = Pipeline([\n",
    "            (\"imputer\", self.fill_nulls()),\n",
    "            (\"scaler\", self.scale()),\n",
    "        ])\n",
    "        cat_pipeline = Pipeline([\n",
    "            (\"dummy\", self.make_dummies()),\n",
    "        ])\n",
    "        full_pipeline = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_columns),\n",
    "            (\"cat\", cat_pipeline, cat_columns),\n",
    "        ])\n",
    "        self.output = full_pipeline.fit_transform(dataset)\n",
    "        return self.output\n",
    "\n",
    "    def cross_validate(self, model, x, y, score_measure=\"neg_mean_squared_error\", folds=10):\n",
    "        \"\"\"Uses the SKLearn Cross_Val_Score to cross-validate one/several models on the training subset\"\"\"\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        scores = cross_val_score(model, x, y, scoring=score_measure, cv=folds)\n",
    "        return scores\n",
    "\n",
    "    def full_analysis(self, model):\n",
    "        \"\"\"Conducts a full data-analysis pipeline on the dataset, including model training, evaluation and tuning\"\"\"\n",
    "        dataset = self.output\n",
    "        X_train, X_test, Y_train, Y_test = self.random_split(dataset)\n",
    "\n",
    "        sqrt_scores = np.sqrt(-self.cross_validate(model, X_train, Y_train, score_measure=\"neg_mean_squared_error\", folds=10))\n",
    "        print(\n",
    "            \"RMSE-scores: \", sqrt_scores,\n",
    "            \"RMSE-mean: \", sqrt_scores.mean(),\n",
    "            \"RMSE-std: \", sqrt_scores.std()\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "dir = 'C:/Users/JesperFrederiksen/PycharmProjects/ML-code/datasets/housing/housing.csv'\n",
    "df = pd.read_csv(dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "pal = Palanthir(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value'] Categorical features: ['ocean_proximity']\n"
     ]
    }
   ],
   "source": [
    "print(f'Numerical features: {pal.features_num}',\n",
    "      f'Categorical features: {pal.features_cat}'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [
    {
     "data": {
      "text/plain": "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n0        -122.23     37.88                41.0        880.0           129.0   \n1        -122.22     37.86                21.0       7099.0          1106.0   \n2        -122.24     37.85                52.0       1467.0           190.0   \n3        -122.25     37.85                52.0       1274.0           235.0   \n4        -122.25     37.85                52.0       1627.0           280.0   \n...          ...       ...                 ...          ...             ...   \n20635    -121.09     39.48                25.0       1665.0           374.0   \n20636    -121.21     39.49                18.0        697.0           150.0   \n20637    -121.22     39.43                17.0       2254.0           485.0   \n20638    -121.32     39.43                18.0       1860.0           409.0   \n20639    -121.24     39.37                16.0       2785.0           616.0   \n\n       population  households  median_income  median_house_value  \\\n0           322.0       126.0         8.3252            452600.0   \n1          2401.0      1138.0         8.3014            358500.0   \n2           496.0       177.0         7.2574            352100.0   \n3           558.0       219.0         5.6431            341300.0   \n4           565.0       259.0         3.8462            342200.0   \n...           ...         ...            ...                 ...   \n20635       845.0       330.0         1.5603             78100.0   \n20636       356.0       114.0         2.5568             77100.0   \n20637      1007.0       433.0         1.7000             92300.0   \n20638       741.0       349.0         1.8672             84700.0   \n20639      1387.0       530.0         2.3886             89400.0   \n\n       ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  \\\n0                            0.0                     0.0   \n1                            0.0                     0.0   \n2                            0.0                     0.0   \n3                            0.0                     0.0   \n4                            0.0                     0.0   \n...                          ...                     ...   \n20635                        0.0                     1.0   \n20636                        0.0                     1.0   \n20637                        0.0                     1.0   \n20638                        0.0                     1.0   \n20639                        0.0                     1.0   \n\n       ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n0                         0.0                       1.0   \n1                         0.0                       1.0   \n2                         0.0                       1.0   \n3                         0.0                       1.0   \n4                         0.0                       1.0   \n...                       ...                       ...   \n20635                     0.0                       0.0   \n20636                     0.0                       0.0   \n20637                     0.0                       0.0   \n20638                     0.0                       0.0   \n20639                     0.0                       0.0   \n\n       ocean_proximity_NEAR OCEAN  \n0                             0.0  \n1                             0.0  \n2                             0.0  \n3                             0.0  \n4                             0.0  \n...                           ...  \n20635                         0.0  \n20636                         0.0  \n20637                         0.0  \n20638                         0.0  \n20639                         0.0  \n\n[20640 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity_&lt;1H OCEAN</th>\n      <th>ocean_proximity_INLAND</th>\n      <th>ocean_proximity_ISLAND</th>\n      <th>ocean_proximity_NEAR BAY</th>\n      <th>ocean_proximity_NEAR OCEAN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20635</th>\n      <td>-121.09</td>\n      <td>39.48</td>\n      <td>25.0</td>\n      <td>1665.0</td>\n      <td>374.0</td>\n      <td>845.0</td>\n      <td>330.0</td>\n      <td>1.5603</td>\n      <td>78100.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20636</th>\n      <td>-121.21</td>\n      <td>39.49</td>\n      <td>18.0</td>\n      <td>697.0</td>\n      <td>150.0</td>\n      <td>356.0</td>\n      <td>114.0</td>\n      <td>2.5568</td>\n      <td>77100.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20637</th>\n      <td>-121.22</td>\n      <td>39.43</td>\n      <td>17.0</td>\n      <td>2254.0</td>\n      <td>485.0</td>\n      <td>1007.0</td>\n      <td>433.0</td>\n      <td>1.7000</td>\n      <td>92300.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20638</th>\n      <td>-121.32</td>\n      <td>39.43</td>\n      <td>18.0</td>\n      <td>1860.0</td>\n      <td>409.0</td>\n      <td>741.0</td>\n      <td>349.0</td>\n      <td>1.8672</td>\n      <td>84700.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20639</th>\n      <td>-121.24</td>\n      <td>39.37</td>\n      <td>16.0</td>\n      <td>2785.0</td>\n      <td>616.0</td>\n      <td>1387.0</td>\n      <td>530.0</td>\n      <td>2.3886</td>\n      <td>89400.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20640 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.make_dummies()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.current_version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [
    {
     "data": {
      "text/plain": "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n0        -122.23     37.88                41.0        880.0           129.0   \n1        -122.22     37.86                21.0       7099.0          1106.0   \n2        -122.24     37.85                52.0       1467.0           190.0   \n3        -122.25     37.85                52.0       1274.0           235.0   \n4        -122.25     37.85                52.0       1627.0           280.0   \n...          ...       ...                 ...          ...             ...   \n20635    -121.09     39.48                25.0       1665.0           374.0   \n20636    -121.21     39.49                18.0        697.0           150.0   \n20637    -121.22     39.43                17.0       2254.0           485.0   \n20638    -121.32     39.43                18.0       1860.0           409.0   \n20639    -121.24     39.37                16.0       2785.0           616.0   \n\n       population  households  median_income  median_house_value  \\\n0           322.0       126.0         8.3252            452600.0   \n1          2401.0      1138.0         8.3014            358500.0   \n2           496.0       177.0         7.2574            352100.0   \n3           558.0       219.0         5.6431            341300.0   \n4           565.0       259.0         3.8462            342200.0   \n...           ...         ...            ...                 ...   \n20635       845.0       330.0         1.5603             78100.0   \n20636       356.0       114.0         2.5568             77100.0   \n20637      1007.0       433.0         1.7000             92300.0   \n20638       741.0       349.0         1.8672             84700.0   \n20639      1387.0       530.0         2.3886             89400.0   \n\n       ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  \\\n0                            0.0                     0.0   \n1                            0.0                     0.0   \n2                            0.0                     0.0   \n3                            0.0                     0.0   \n4                            0.0                     0.0   \n...                          ...                     ...   \n20635                        0.0                     1.0   \n20636                        0.0                     1.0   \n20637                        0.0                     1.0   \n20638                        0.0                     1.0   \n20639                        0.0                     1.0   \n\n       ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n0                         0.0                       1.0   \n1                         0.0                       1.0   \n2                         0.0                       1.0   \n3                         0.0                       1.0   \n4                         0.0                       1.0   \n...                       ...                       ...   \n20635                     0.0                       0.0   \n20636                     0.0                       0.0   \n20637                     0.0                       0.0   \n20638                     0.0                       0.0   \n20639                     0.0                       0.0   \n\n       ocean_proximity_NEAR OCEAN  \n0                             0.0  \n1                             0.0  \n2                             0.0  \n3                             0.0  \n4                             0.0  \n...                           ...  \n20635                         0.0  \n20636                         0.0  \n20637                         0.0  \n20638                         0.0  \n20639                         0.0  \n\n[20640 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity_&lt;1H OCEAN</th>\n      <th>ocean_proximity_INLAND</th>\n      <th>ocean_proximity_ISLAND</th>\n      <th>ocean_proximity_NEAR BAY</th>\n      <th>ocean_proximity_NEAR OCEAN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20635</th>\n      <td>-121.09</td>\n      <td>39.48</td>\n      <td>25.0</td>\n      <td>1665.0</td>\n      <td>374.0</td>\n      <td>845.0</td>\n      <td>330.0</td>\n      <td>1.5603</td>\n      <td>78100.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20636</th>\n      <td>-121.21</td>\n      <td>39.49</td>\n      <td>18.0</td>\n      <td>697.0</td>\n      <td>150.0</td>\n      <td>356.0</td>\n      <td>114.0</td>\n      <td>2.5568</td>\n      <td>77100.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20637</th>\n      <td>-121.22</td>\n      <td>39.43</td>\n      <td>17.0</td>\n      <td>2254.0</td>\n      <td>485.0</td>\n      <td>1007.0</td>\n      <td>433.0</td>\n      <td>1.7000</td>\n      <td>92300.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20638</th>\n      <td>-121.32</td>\n      <td>39.43</td>\n      <td>18.0</td>\n      <td>1860.0</td>\n      <td>409.0</td>\n      <td>741.0</td>\n      <td>349.0</td>\n      <td>1.8672</td>\n      <td>84700.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20639</th>\n      <td>-121.24</td>\n      <td>39.37</td>\n      <td>16.0</td>\n      <td>2785.0</td>\n      <td>616.0</td>\n      <td>1387.0</td>\n      <td>530.0</td>\n      <td>2.3886</td>\n      <td>89400.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20640 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.fill_nulls()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.current_version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "pal.restore(toVersion=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.current_version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pal.transformation_history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "data": {
      "text/plain": "'Restored to version 0'"
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.transformation_history[3].get('transformation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ocean_proximity_<1H OCEAN', 'ocean_proximity_INLAND', 'ocean_proximity_ISLAND', 'ocean_proximity_NEAR BAY', 'ocean_proximity_NEAR OCEAN'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[317], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfill_nulls\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[305], line 91\u001B[0m, in \u001B[0;36mPalanthir.fill_nulls\u001B[1;34m(self, strategy, store)\u001B[0m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfill_nulls\u001B[39m(\u001B[38;5;28mself\u001B[39m, strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmedian\u001B[39m\u001B[38;5;124m\"\u001B[39m, store\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m     90\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Uses the SKLearn SimpleImputer to fill out any missing values in the numerical features of the dataset\"\"\"\u001B[39;00m\n\u001B[1;32m---> 91\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures_num\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SimpleImputer\n\u001B[0;32m     93\u001B[0m     imputed_data \u001B[38;5;241m=\u001B[39m SimpleImputer(strategy\u001B[38;5;241m=\u001B[39mstrategy)\u001B[38;5;241m.\u001B[39mfit_transform(dataset)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML-code\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3813\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3811\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   3812\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 3813\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   3815\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML-code\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6067\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6068\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6070\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6072\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6073\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6074\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML-code\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6132\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['ocean_proximity_<1H OCEAN', 'ocean_proximity_INLAND', 'ocean_proximity_ISLAND', 'ocean_proximity_NEAR BAY', 'ocean_proximity_NEAR OCEAN'] not in index\""
     ]
    }
   ],
   "source": [
    "pal.fill_nulls()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.current_version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ocean_proximity_<1H OCEAN', 'ocean_proximity_INLAND', 'ocean_proximity_ISLAND', 'ocean_proximity_NEAR BAY', 'ocean_proximity_NEAR OCEAN'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[319], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPCA\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[305], line 74\u001B[0m, in \u001B[0;36mPalanthir.PCA\u001B[1;34m(self, n_components, store)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mPCA\u001B[39m(\u001B[38;5;28mself\u001B[39m, n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.80\u001B[39m, store\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m---> 74\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures_num\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdecomposition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PCA\n\u001B[0;32m     76\u001B[0m     pca_data \u001B[38;5;241m=\u001B[39m PCA(n_components\u001B[38;5;241m=\u001B[39mn_components)\u001B[38;5;241m.\u001B[39mfit_transform(dataset)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML-code\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3813\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3811\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   3812\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 3813\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   3815\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML-code\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6067\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6068\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6070\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6072\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6073\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6074\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML-code\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6132\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['ocean_proximity_<1H OCEAN', 'ocean_proximity_INLAND', 'ocean_proximity_ISLAND', 'ocean_proximity_NEAR BAY', 'ocean_proximity_NEAR OCEAN'] not in index\""
     ]
    }
   ],
   "source": [
    "pal.PCA()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.current_version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "data": {
      "text/plain": "'Performed Principal Component Analysis'"
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal.transformation_history[5].get('transformation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_columns = []\n",
    "cat_columns = []\n",
    "num_pipeline = Pipeline([])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "num_pipeline.steps.append(['imputer',SimpleImputer(strategy=\"median\")])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "data": {
      "text/plain": "[['imputer', SimpleImputer(strategy='median')],\n ['imputer', SimpleImputer(strategy='median')],\n None,\n []]"
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [],
   "source": [
    "num_pipeline.steps.append(['imputer',SimpleImputer(strategy=\"median\")])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [],
   "source": [
    "num_pipeline.steps.append([]) if 1==3 else None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "data": {
      "text/plain": "[['imputer', SimpleImputer(strategy='median')],\n ['imputer', SimpleImputer(strategy='median')],\n None,\n [],\n [],\n [],\n []]"
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
